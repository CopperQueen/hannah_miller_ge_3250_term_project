{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 1: Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 11:21:42,257 - INFO - Libraries and custom functions imported.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.lines import Line2D # For custom legend handles\n",
    "from datetime import date # For type hinting if using dates\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "# Configure logging (set level, format, etc.) - Basic example\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True) # force=True might be needed in notebooks\n",
    "\n",
    "# Add functions directory to path to import custom modules\n",
    "# Assuming the notebook is run from the project root directory\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import importlib\n",
    "# Import the data fetching and loading functions\n",
    "from functions.data_fetching.earthquake_data import fetch_and_load_earthquake_data\n",
    "from functions.data_fetching.plate_data import load_plate_boundaries\n",
    "from functions.data_fetching.natural_earth_downloader import load_natural_earth_data\n",
    "import functions.data_processing\n",
    "# Import the plotting function\n",
    "import functions.plotting\n",
    "\n",
    "logging.info(\"Libraries and custom functions imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2: Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the minimum magnitude for earthquake data\n",
    "min_eq_magnitude = 1.0\n",
    "\n",
    "# Define target CRS (used by loading functions by default)\n",
    "target_crs_epsg = \"EPSG:4326\"\n",
    "\n",
    "# Define date range (optional, defaults in function are ~last year)\n",
    "# Set to None if not using specific dates, otherwise define as string or date object\n",
    "start_date = \"2020-01-01\" # Example: \"2024-01-01\" or date(2024, 1, 1)\n",
    "end_date =  \"2024-12-31\"   # Example: \"2024-12-31\" or date(2024, 12, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 3: Load Data using Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 11:21:42,505 - INFO - Loading earthquake data (min magnitude: 1.0, target CRS: EPSG:4326)...\n",
      "2025-04-08 11:21:42,506 - INFO - Processing earthquake data from 2020-01-01 to 2024-12-31 (inclusive)...\n",
      "2025-04-08 11:21:42,599 - INFO - All daily files already exist locally.\n",
      "2025-04-08 11:21:42,600 - INFO - Loading daily GeoJSON files...\n",
      "2025-04-08 11:23:46,805 - INFO - Concatenating data from 1827 daily files...\n",
      "c:\\Users\\Hannah Miller Young\\OneDrive\\Documents\\GE3250 Computational Geoscience\\hannah_miller_term_project\\functions\\data_fetching\\earthquake_data.py:219: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_gdf = pd.concat(daily_gdfs, ignore_index=True)\n",
      "2025-04-08 11:23:49,915 - INFO - Successfully loaded and combined 552787 total earthquakes.\n",
      "2025-04-08 11:23:49,928 - INFO - Reprojecting combined earthquake data from EPSG:4979 to EPSG:4326...\n",
      "2025-04-08 11:23:53,839 - INFO - Reprojection successful. Final CRS: EPSG:4326\n",
      "2025-04-08 11:23:56,366 - INFO - -> Successfully loaded 552787 earthquakes. CRS: EPSG:4326\n",
      "2025-04-08 11:23:56,369 - INFO - \n",
      "Loading tectonic plate boundary data (target CRS: EPSG:4326)...\n",
      "2025-04-08 11:23:56,376 - INFO - Found existing combined plate boundary file: resources\\plate_boundaries\\combined_plate_boundaries.shp\n",
      "2025-04-08 11:23:56,526 - INFO - Successfully loaded 514 features from combined file. CRS: EPSG:4326\n",
      "2025-04-08 11:23:56,538 - INFO - Combined plate boundary data is already in target CRS (EPSG:4326).\n",
      "2025-04-08 11:23:56,542 - INFO - -> Successfully loaded 514 plate boundary features. CRS: EPSG:4326\n",
      "2025-04-08 11:23:56,546 - INFO - \n",
      "Loading Natural Earth 50m countries and 10m lakes data (target CRS: EPSG:4326)...\n",
      "2025-04-08 11:23:56,562 - INFO - Loading Natural Earth 'countries' data from resources/natural_earth_boundaries\\ne_50m_admin_0_countries.zip...\n",
      "2025-04-08 11:23:57,041 - INFO - Successfully loaded 242 features for 'countries'. Original CRS: EPSG:4326\n",
      "2025-04-08 11:23:57,049 - INFO - 'countries' data is already in target CRS (EPSG:4326).\n",
      "2025-04-08 11:23:57,053 - INFO - Loading Natural Earth 'lakes' data from resources/natural_earth_boundaries\\ne_10m_lakes.zip...\n",
      "2025-04-08 11:23:57,637 - INFO - Successfully loaded 1355 features for 'lakes'. Original CRS: EPSG:4326\n",
      "2025-04-08 11:23:57,646 - INFO - 'lakes' data is already in target CRS (EPSG:4326).\n",
      "2025-04-08 11:23:57,649 - INFO - -> Successfully loaded 242 countries. CRS: EPSG:4326\n",
      "2025-04-08 11:23:57,652 - INFO - -> Successfully loaded 1355 lakes. CRS: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "# Load Earthquake Data\n",
    "logging.info(f\"Loading earthquake data (min magnitude: {min_eq_magnitude}, target CRS: {target_crs_epsg})...\")\n",
    "earthquake_gdf = fetch_and_load_earthquake_data(\n",
    "    min_magnitude=min_eq_magnitude,\n",
    "    target_crs=target_crs_epsg,\n",
    "    start_date=start_date, # Pass defined start_date\n",
    "    end_date=end_date      # Pass defined end_date\n",
    ")\n",
    "# drop columns we don't need\n",
    "earthquake_gdf.drop(columns=['tz', 'url', 'detail','title', 'updated','sources','ids','types'], inplace=True)\n",
    "if earthquake_gdf is not None:\n",
    "    logging.info(f\"-> Successfully loaded {len(earthquake_gdf)} earthquakes. CRS: {earthquake_gdf.crs}\")\n",
    "else:\n",
    "    logging.error(\"-> Failed to load earthquake data.\")\n",
    "\n",
    "# Load Plate Boundary Data\n",
    "logging.info(f\"\\nLoading tectonic plate boundary data (target CRS: {target_crs_epsg})...\")\n",
    "plate_gdf = load_plate_boundaries(target_crs=target_crs_epsg)\n",
    "if plate_gdf is not None:\n",
    "    logging.info(f\"-> Successfully loaded {len(plate_gdf)} plate boundary features. CRS: {plate_gdf.crs}\")\n",
    "else:\n",
    "    logging.error(\"-> Failed to load plate boundary data.\")\n",
    "\n",
    "# Load Natural Earth Data\n",
    "logging.info(f\"\\nLoading Natural Earth 50m countries and 10m lakes data (target CRS: {target_crs_epsg})...\")\n",
    "natural_earth_data = load_natural_earth_data(target_crs=target_crs_epsg)\n",
    "ne_countries_gdf = natural_earth_data.get('countries') # Changed key and variable name\n",
    "ne_lakes_gdf = natural_earth_data.get('lakes')\n",
    "\n",
    "if ne_countries_gdf is not None:\n",
    "    logging.info(f\"-> Successfully loaded {len(ne_countries_gdf)} countries. CRS: {ne_countries_gdf.crs}\")\n",
    "else:\n",
    "    logging.error(\"-> Failed to load Natural Earth countries.\")\n",
    "\n",
    "if ne_lakes_gdf is not None:\n",
    "    logging.info(f\"-> Successfully loaded {len(ne_lakes_gdf)} lakes. CRS: {ne_lakes_gdf.crs}\")\n",
    "else:\n",
    "    logging.error(\"-> Failed to load Natural Earth lakes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4: Check Loaded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 11:23:57,830 - INFO - Essential data (Plates, Earthquakes) loaded successfully.\n",
      "2025-04-08 11:23:57,832 - INFO - Natural Earth basemap data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Verify if essential data for plotting was loaded successfully\n",
    "can_plot_plates_eq = all(gdf is not None for gdf in [plate_gdf, earthquake_gdf])\n",
    "can_plot_ne = all(gdf is not None for gdf in [ne_countries_gdf, ne_lakes_gdf]) # Basemap is optional, updated variable\n",
    "\n",
    "if not can_plot_plates_eq:\n",
    "    logging.error(\"Error: Cannot proceed with plotting as Plate Boundary or Earthquake data failed to load.\")\n",
    "else:\n",
    "    logging.info(\"Essential data (Plates, Earthquakes) loaded successfully.\")\n",
    "    if not can_plot_ne:\n",
    "        logging.warning(\"Warning: Natural Earth basemap data failed to load. Plot will be generated without basemap.\")\n",
    "    else:\n",
    "        logging.info(\"Natural Earth basemap data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the UTM Zone for every earthquak point, project the point to that utm zone in a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 11:24:03,845 - INFO - earthquake_gdf geometry is 3D. Converting to 2D.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c20428dc1e04d01a1c60d4a425da891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dask Apply:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 11:26:07,508 - INFO - Calculating UTM info and reprojecting geometry using swifter...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_processing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Apply the combined function row-wise using swifter\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Pass the source_crs as an argument\u001b[39;00m\n\u001b[32m     25\u001b[39m earthquake_with_utm_gdf = earthquake_gdf.query(\u001b[33m'\u001b[39m\u001b[33mmag>5\u001b[39m\u001b[33m'\u001b[39m).copy()\n\u001b[32m     26\u001b[39m result_series = earthquake_with_utm_gdf.swifter.apply(\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43mdata_processing\u001b[49m.get_utm_info_and_reproject,\n\u001b[32m     28\u001b[39m     source_crs=earthquake_with_utm_gdf.crs, \u001b[38;5;66;03m# Pass the source CRS here\u001b[39;00m\n\u001b[32m     29\u001b[39m     axis=\u001b[32m1\u001b[39m\n\u001b[32m     30\u001b[39m )\n\u001b[32m     31\u001b[39m earthquake_with_utm_gdf[[\u001b[33m'\u001b[39m\u001b[33mutm_zone\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mutm_epsg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mutm_geometry\u001b[39m\u001b[33m'\u001b[39m]] = gpd.GeoDataFrame(\n\u001b[32m     32\u001b[39m     result_series.tolist(),\n\u001b[32m     33\u001b[39m     index=earthquake_with_utm_gdf.index\n\u001b[32m     34\u001b[39m )\n\u001b[32m     35\u001b[39m earthquake_with_utm_gdf.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'data_processing' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Added for pd.isna\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import math\n",
    "import swifter # Import swifter\n",
    "import logging # Make sure logging is configured elsewhere\n",
    "\n",
    "\n",
    "# Make our earthquake location with a depth a 2d point. be efficient for testing and only do this if we haven't done it before\n",
    "if not earthquake_gdf.empty and 'geometry' in earthquake_gdf.columns and earthquake_gdf['geometry'].iloc[0] is not None and hasattr(earthquake_gdf['geometry'].iloc[0], 'has_z') and earthquake_gdf['geometry'].iloc[0].has_z:\n",
    "    logging.info(\"earthquake_gdf geometry is 3D. Converting to 2D.\")\n",
    "    # Ensure we only apply to actual geometry objects, handle None\n",
    "    earthquake_gdf['geometry'] = earthquake_gdf['geometry'].swifter.apply(\n",
    "        lambda geom: Point(geom.x, geom.y) if geom and hasattr(geom, 'x') else None\n",
    "    )\n",
    "else:\n",
    "    logging.info(\"earthquake_gdf geometry is not 3D or conversion not needed. Skipping conversion.\")\n",
    "\n",
    "# --- Modified Apply Call ---\n",
    "logging.info(\"Calculating UTM info and reprojecting geometry using swifter...\")\n",
    "\n",
    "# Apply the combined function row-wise using swifter\n",
    "# Pass the source_crs as an argument\n",
    "\n",
    "earthquake_with_utm_gdf = earthquake_gdf.query('mag>5').copy()\n",
    "result_series = earthquake_with_utm_gdf.swifter.apply(\n",
    "    data_processing.get_utm_info_and_reproject,\n",
    "    source_crs=earthquake_with_utm_gdf.crs, # Pass the source CRS here\n",
    "    axis=1\n",
    ")\n",
    "earthquake_with_utm_gdf[['utm_zone', 'utm_epsg', 'utm_geometry']] = gpd.GeoDataFrame(\n",
    "    result_series.tolist(),\n",
    "    index=earthquake_with_utm_gdf.index\n",
    ")\n",
    "earthquake_with_utm_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from functions.spatial_analysis import calculate_distance_to_plate\n",
    "\n",
    "earthquake_gdf_with_distances = gpd.GeoDataFrame(calculate_distance_to_plate(earthquake_with_utm_gdf, plate_gdf, max_workers=4, log_level='NONE'))\n",
    "\n",
    "earthquake_gdf_with_distances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(functions.plotting) # Using this so I can edit the plotting.py file re-import without having to restart my kernel and load all the data which takes a good deal of time.\n",
    "\n",
    "if can_plot_plates_eq:\n",
    "    functions.plotting.plot_earthquake_plate_map( # Ensure using the reloaded module\n",
    "        earthquake_gdf=earthquake_gdf_with_distances,\n",
    "        plate_gdf=plate_gdf,\n",
    "        ne_land_gdf=ne_countries_gdf, # Pass countries to the renamed parameter\n",
    "        ne_lakes_gdf=ne_lakes_gdf,\n",
    "        min_magnitude=min_eq_magnitude,\n",
    "        start_date=start_date, # Pass the defined start_date (could be None)\n",
    "        end_date=end_date,     # Pass the defined end_date (could be None)\n",
    "        target_crs_epsg=target_crs_epsg\n",
    "    )\n",
    "else:\n",
    "    logging.warning(\"Skipping plot generation due to data loading errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake_gdf_with_distances.query('distance_to_plate>0').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the plate ridgeds in order of activity\n",
    "earthquake_gdf_with_distances.groupby('nearest_plate_geogdesc').size().reset_index(name='count').sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance From Ridge and Magnitude Analysis and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts by ridge type\n",
    "earthquake_gdf_with_distances.groupby('nearest_plate_boundary_t').size().reset_index(name='count').sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming earthquake_gdf_with_distances is your DataFrame\n",
    "\n",
    "# Convert distance to kilometers\n",
    "earthquake_gdf_with_distances['distance_to_plate_km'] = earthquake_gdf_with_distances['distance_to_plate'] / 1000\n",
    "\n",
    "# Get unique boundary types, excluding those where *all* distances are NaN\n",
    "unique_boundaries = earthquake_gdf_with_distances.dropna(subset=['distance_to_plate_km'])['nearest_plate_boundary_t'].unique()\n",
    "num_plots = len(unique_boundaries)\n",
    "\n",
    "# Create the figure and axes for the horizontal plots\n",
    "fig, axes = plt.subplots(1, num_plots, figsize=(12, 4))  # 1 row, num_plots columns, adjust figsize as needed\n",
    "if num_plots == 1:  # Handle case where there's only one subplot (axes becomes a single Axes object)\n",
    "    axes = [axes]  # Wrap in a list to make it iterable\n",
    "\n",
    "# Iterate through the boundary types and create the histograms\n",
    "for i, boundary_type in enumerate(unique_boundaries):\n",
    "    df_subset = earthquake_gdf_with_distances[earthquake_gdf_with_distances['nearest_plate_boundary_t'] == boundary_type].dropna(subset=['distance_to_plate_km'])\n",
    "\n",
    "    axes[i].hist(df_subset['distance_to_plate_km'], bins=20, range=(0, 10000))  # Adjust number of bins as needed, set range\n",
    "    axes[i].set_title(f\"Distance to Plate Distribution ({boundary_type})\")\n",
    "    axes[i].set_xlabel(\"Distance to Plate (km)\")\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "    axes[i].set_xlim(0, 10000)  # Set x-axis limit\n",
    "\n",
    "# Adjust layout to prevent overlapping titles/labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np # For example data\n",
    "\n",
    "## --- Make sure calculate_ridge_distance_likelihood is defined as before ---\n",
    "def calculate_ridge_distance_likelihood(df, distance_column='distance_to_plate_km', boundary_type_column='nearest_plate_boundary_t', distance_thresholds=[100, 250, 500, 1000, 2000]):\n",
    "    \"\"\"\n",
    "    Calculates the likelihood (percentage) of earthquakes occurring within specified distance thresholds for each ridge type. Handles empty input DataFrame.\n",
    "    (Function content remains the same as the robust version from previous steps)\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        cols = [f\"<{th}km\" for th in distance_thresholds] + [\"Further Away\"]\n",
    "        return pd.DataFrame(columns=cols)\n",
    "    df_calc = df.copy(); df_calc = df_calc.dropna(subset=[distance_column, boundary_type_column])\n",
    "    if df_calc.empty:\n",
    "        cols = [f\"<{th}km\" for th in distance_thresholds] + [\"Further Away\"]; return pd.DataFrame(columns=cols)\n",
    "    ridge_types = df_calc[boundary_type_column].unique()\n",
    "    if len(ridge_types) == 0:\n",
    "         cols = [f\"<{th}km\" for th in distance_thresholds] + [\"Further Away\"]; return pd.DataFrame(columns=cols)\n",
    "    results = {}\n",
    "    for ridge_type in ridge_types:\n",
    "        ridge_data = df_calc[df_calc[boundary_type_column] == ridge_type][distance_column]; total_count = len(ridge_data)\n",
    "        results[ridge_type] = {}\n",
    "        if total_count == 0:\n",
    "            likelihood_further = 0.0; results[ridge_type] = {f\"<{threshold}km\": 0.0 for threshold in distance_thresholds}\n",
    "        else:\n",
    "            for threshold in distance_thresholds: results[ridge_type][f\"<{threshold}km\"] = (len(ridge_data[ridge_data <= threshold]) / total_count) * 100\n",
    "            likelihood_further = (len(ridge_data[ridge_data > distance_thresholds[-1]]) / total_count) * 100\n",
    "        results[ridge_type][\"Further Away\"] = likelihood_further\n",
    "    results_df = pd.DataFrame(results).T; results_df = results_df.sort_index(); results_df.index.name = \"Ridge Type\"\n",
    "    expected_cols = [f\"<{th}km\" for th in distance_thresholds] + [\"Further Away\"]\n",
    "    for col in expected_cols:\n",
    "        if col not in results_df.columns: results_df[col] = 0.0\n",
    "    results_df = results_df[expected_cols]\n",
    "    return results_df\n",
    "\n",
    "def visualize_ridge_distance_likelihood_combined(\n",
    "    df, distance_column='distance_to_plate',\n",
    "    boundary_type_column='nearest_plate_boundary_t',\n",
    "    max_distance=10000, \n",
    "    minmag=None, \n",
    "    mag_column='mag',\n",
    "    distance_thresholds=[100, 250, 500, 1000, 2000],\n",
    "    color_by=None # <-- New optional parameter\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes earthquake distances (boxplot) and likelihoods (table).\n",
    "    Adjusts layout for many categories, rotates labels, increases table spacing.\n",
    "    Optionally colors boxplot by 'color_by' column and adds a legend.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with earthquake data.\n",
    "        distance_column (str): Column name for distance (km).\n",
    "        boundary_type_column (str): Column name for boundary type (x-axis).\n",
    "        max_distance (int): Max distance for y-axis.\n",
    "        minmag (float, optional): Minimum magnitude filter. Defaults to None.\n",
    "        mag_column (str): Column name for magnitude. Defaults to 'mag'.\n",
    "        distance_thresholds (list): Distance thresholds for likelihood calculation.\n",
    "        color_by (str, optional): Column name to use for coloring the boxplot\n",
    "                                   (hue). If None, color maps to x-axis category.\n",
    "                                   Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    orig_minmag = minmag\n",
    "\n",
    "    # --- Data Preparation and Filtering ---\n",
    "    df_filtered = df.copy()\n",
    "    required_cols = [distance_column, boundary_type_column, mag_column]\n",
    "    if color_by and color_by not in required_cols:\n",
    "         required_cols.append(color_by) # Ensure color_by column is checked for NaNs\n",
    "\n",
    "    df_filtered = df_filtered.dropna(subset=required_cols)\n",
    "\n",
    "    if minmag is not None:\n",
    "        df_filtered = df_filtered[df_filtered[mag_column] >= minmag]\n",
    "        actual_minmag_used = minmag\n",
    "    else:\n",
    "        if df_filtered.empty:\n",
    "             print(\"Warning: DataFrame empty after NaN drop.\")\n",
    "             return\n",
    "        actual_minmag_used = df_filtered[mag_column].min()\n",
    "\n",
    "    df_filtered = df_filtered[df_filtered[distance_column] <= max_distance]\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        filter_mag_str = f\"minmag={orig_minmag:.2f}\" if orig_minmag is not None else \"no minmag filter\"\n",
    "        print(f\"Warning: No data left after filtering ({filter_mag_str}, max_distance={max_distance}).\")\n",
    "        return\n",
    "\n",
    "    # --- Validate color_by column ---\n",
    "    use_hue = False\n",
    "    if color_by:\n",
    "        if color_by in df_filtered.columns:\n",
    "            use_hue = True\n",
    "            print(f\"Coloring boxplot by column: '{color_by}'\")\n",
    "        else:\n",
    "            print(f\"Warning: 'color_by' column '{color_by}' not found in filtered data. Ignoring.\")\n",
    "            color_by = None # Reset to None if invalid\n",
    "\n",
    "\n",
    "    # --- Calculate Likelihoods ---\n",
    "    results_df = calculate_ridge_distance_likelihood(df_filtered, distance_column, boundary_type_column, distance_thresholds)\n",
    "\n",
    "    # --- Plotting Setup ---\n",
    "    num_categories = len(df_filtered[boundary_type_column].unique())\n",
    "    base_fig_width = 8\n",
    "    # --- MODIFICATION: Increase width per category slightly ---\n",
    "    width_per_category = 0.55 # OLD: 0.4 or 0.5. NEW: Try 0.55\n",
    "    min_fig_width = 12\n",
    "    fig_width = max(min_fig_width, base_fig_width + num_categories * width_per_category)\n",
    "    fig_height = 13\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        2, 1,\n",
    "        figsize=(fig_width, fig_height),\n",
    "        gridspec_kw={'height_ratios': [2, 3]} # Keep table area larger\n",
    "    )\n",
    "\n",
    "    # --- Boxplot (Top Axes) ---\n",
    "    plot_kwargs = {\n",
    "        'x': boundary_type_column,\n",
    "        'y': distance_column,\n",
    "        'data': df_filtered,\n",
    "        'ax': axes[0]\n",
    "    }\n",
    "    if use_hue:\n",
    "        plot_kwargs['hue'] = color_by\n",
    "        plot_kwargs['palette'] = 'Set2' # Use a categorical palette for hue\n",
    "    else:\n",
    "        plot_kwargs['palette'] = 'viridis' # Keep original behavior if no hue\n",
    "\n",
    "    sns.boxplot(**plot_kwargs)\n",
    "\n",
    "    title_minmag_str = f\"{actual_minmag_used:.2f}\"\n",
    "    axes[0].set_title(f\"Distribution of Earthquake Distances to Different Ridge Types (mag >= {title_minmag_str})\", fontsize=14)\n",
    "    axes[0].set_xlabel(\"\")\n",
    "    axes[0].set_ylabel(\"Distance (km)\", fontsize=12)\n",
    "    axes[0].set_ylim(0, max_distance)\n",
    "    axes[0].tick_params(axis='x', rotation=90)\n",
    "    axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=90)\n",
    "\n",
    "    # --- Add Legend if using hue ---\n",
    "    if use_hue:\n",
    "        # Place legend outside the top right corner of the plot\n",
    "        axes[0].legend(title=color_by, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0.)\n",
    "        # Adjust right margin to make space for the legend\n",
    "        right_margin = 0.85 # Shrink plot area to 85% to fit legend\n",
    "    else:\n",
    "        # Use more of the figure width if no legend\n",
    "        right_margin = 0.98\n",
    "\n",
    "    # --- Table (Bottom Axes) ---\n",
    "    axes[1].axis('off')\n",
    "    if results_df.empty:\n",
    "        print(\"Warning: Likelihood calculation resulted in empty data. Skipping table.\")\n",
    "        axes[1].text(0.5, 0.5, \"No likelihood data to display.\", ha='center', va='center', fontsize=12)\n",
    "    else:\n",
    "        formatted_results_df = results_df.applymap(lambda x: f\"{x:.2f}\")\n",
    "        axes[1].text(0.5, 0.95,\n",
    "                     \"Likelihood of Earthquake Distance by Ridge Type (%)\",\n",
    "                     ha='center', va='top', fontsize=12, transform=axes[1].transAxes)\n",
    "        table_bbox = [0.05, 0.0, 0.9, 0.80]\n",
    "        table = axes[1].table(cellText=formatted_results_df.values,\n",
    "                              colLabels=formatted_results_df.columns,\n",
    "                              rowLabels=formatted_results_df.index,\n",
    "                              loc='center', cellLoc='center', bbox=table_bbox)\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(10)\n",
    "        table.scale(1.2, 2.4) # Keep generous row spacing\n",
    "\n",
    "    # --- Final Layout Adjustments ---\n",
    "    # Adjust bottom margin for labels AND right margin for potential legend\n",
    "    plt.subplots_adjust(bottom=0.30, right=right_margin)\n",
    "    # Alternatively, use tight_layout with rect, which might handle margins better together\n",
    "    # plt.tight_layout(rect=[0, 0.05, right_margin, 0.95]) # Adjust rect based on legend presence\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (assuming 'earthquake_gdf_with_distances' DataFrame exists):\n",
    "visualize_ridge_distance_likelihood_combined(earthquake_gdf_with_distances, distance_column='distance_to_plate', boundary_type_column='nearest_plate_boundary_t', distance_thresholds=[100, 250, 500, 1000, 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "def analyze_ridge_likelihood_difference(df, distance_column='distance_to_plate', boundary_type_column='nearest_plate_boundary_t', distance_threshold=100, ridge_type=None):\n",
    "    \"\"\"\n",
    "    Analyzes if there is a statistically significant difference in the likelihood of earthquakes occurring within a certain distance\n",
    "    of a specific ridge type compared to other ridge types.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing earthquake data and ridge information.\n",
    "        distance_column (str): The name of the column containing the distance to the plate boundary (in km).\n",
    "        boundary_type_column (str): The name of the column indicating the type of plate boundary.\n",
    "        distance_threshold (int): The distance threshold (in km) to analyze.\n",
    "        ridge_type (str, optional): The specific ridge type to compare against others. If None, the function iterates through\n",
    "                                      each ridge type, comparing it against all others.\n",
    "\n",
    "    Returns:\n",
    "       dict: A dictionary of dictionaries. The outer dictionary is keyed by ridge_type.\n",
    "              The inner dictionary contains the following keys:\n",
    "                  - 'compared_to' (str): Ridge type being compared against.\n",
    "                  - 'statistic' (float): The Mann-Whitney U statistic.\n",
    "                  - 'pvalue' (float): The p-value from the Mann-Whitney U test.\n",
    "                  - 'interpretation' (str): Interpretation of the statistical significance.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df = df.dropna(subset=[distance_column, boundary_type_column])\n",
    "\n",
    "    results = {}  # Store results for each ridge type\n",
    "\n",
    "    # Get unique ridge types\n",
    "    ridge_types = df[boundary_type_column].unique()\n",
    "\n",
    "\n",
    "    if ridge_type is None: #Iterate over Ridge Types\n",
    "        ridge_types_to_analyze = ridge_types\n",
    "    else: # analyze one ridge type at a time\n",
    "        ridge_types_to_analyze = [ridge_type]\n",
    "\n",
    "    for ridge_type_to_analyze in ridge_types_to_analyze:\n",
    "\n",
    "        results[ridge_type_to_analyze] = {} #Initialize dictionary\n",
    "\n",
    "        for other_ridge_type in ridge_types: #Compare one at a time\n",
    "\n",
    "            if ridge_type_to_analyze == other_ridge_type:\n",
    "                continue #skip self\n",
    "\n",
    "            results[ridge_type_to_analyze][other_ridge_type] = {} #Initialize the dictionary\n",
    "\n",
    "            # Create binary variable for earthquakes within the specified distance of the current ridge type.\n",
    "            is_ridge = (df[boundary_type_column] == ridge_type_to_analyze)\n",
    "            is_within_threshold = (df[distance_column] <= distance_threshold)\n",
    "\n",
    "            #Here's where you went wrong -- the groups were being compared ONLY with them, not with ALL data points for each ridge type\n",
    "            ridge_group = is_within_threshold[is_ridge] #Only where it IS that ridge type and if it's W/IN distance\n",
    "            other_group = is_within_threshold[df[boundary_type_column] == other_ridge_type] #\n",
    "\n",
    "            if len(ridge_group) == 0 or len(other_group) == 0:\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['compared_to'] = other_ridge_type\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['statistic'] = None\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['pvalue'] = None\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['interpretation'] = \"Insufficient data\"\n",
    "                continue  # Skip the test if either group is empty\n",
    "\n",
    "            # Perform Mann-Whitney U test\n",
    "            try:\n",
    "                u_statistic, p_value = stats.mannwhitneyu(ridge_group, other_group, alternative='greater')\n",
    "            except ValueError as e:\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['compared_to'] = other_ridge_type\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['statistic'] = None\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['pvalue'] = None\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['interpretation'] = f\"Error performing test: {e}\"\n",
    "                continue\n",
    "\n",
    "            # Interpretation based on p-value\n",
    "            alpha = 0.05\n",
    "            if p_value < alpha:\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['compared_to'] = other_ridge_type\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['statistic'] = u_statistic\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['pvalue'] = p_value\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['interpretation'] = f\"Earthquakes are significantly more likely to occur within {distance_threshold}km of {ridge_type_to_analyze} compared to {other_ridge_type}.\"\n",
    "            else:\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['compared_to'] = other_ridge_type\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['statistic'] = u_statistic\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['pvalue'] = p_value\n",
    "                results[ridge_type_to_analyze][other_ridge_type]['interpretation'] = f\"There is no significant difference in the likelihood of earthquakes occurring within {distance_threshold}km of {ridge_type_to_analyze} compared to {other_ridge_type}.\"\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example Usage\n",
    "results = analyze_ridge_likelihood_difference(earthquake_gdf_with_distances, distance_threshold=100) #Analyze with distance threshold as 100\n",
    "for ridge_type, comparisons in results.items():\n",
    "    print(f\"Results for {ridge_type}:\")\n",
    "    for other_ridge, data in comparisons.items():\n",
    "        print(f\"  Compared to {other_ridge}:\")\n",
    "        print(f\"    Statistic: {data.get('statistic')}\")\n",
    "        print(f\"    P-value: {data.get('pvalue')}\")\n",
    "        print(f\"    Interpretation: {data['interpretation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the provided results, we can make the following statements about the likelihood of earthquakes occurring within 100km of different ridge types:\n",
    "\n",
    "*   **Trenches vs. Other Ridge Types:** Earthquakes are significantly more likely to occur within 100km of trenches compared to both ridges and transform faults. This suggests that trenches are a more seismically active environment in close proximity (within 100km) than the other two.\n",
    "*   **Transform Faults vs. Ridges:** Earthquakes are significantly more likely to occur within 100km of transform faults compared to ridges. This suggests that transform faults also represent a more seismically active setting within 100km than ridges.\n",
    "*   **Ridges vs. All Others:** There is *no* statistically significant difference in earthquake likelihood between ridges and either trenches or transform faults. This suggests that ridges, at least within 100km, are the *least* likely of these three plate boundary types to have nearby earthquakes.\n",
    "*   **Transform Faults vs Trenches:** Earthquakes are not significantly different between transform faults and trenches.\n",
    "\n",
    "**In summary,** these findings suggest a hierarchy in terms of the likelihood of earthquakes occurring within 100km of these plate boundary types:\n",
    "\n",
    "**Trenches > Transform Faults > Ridges.**\n",
    "\n",
    "Specifically, we can say:\n",
    "\n",
    "1.  Earthquakes are generally more concentrated near trenches within a 100km radius compared to the others.\n",
    "2.  Earthquakes are more common near transform faults compared to ridges within 100km, but the difference is not always significant compared to trenches.\n",
    "3.  Ridge plate boundaries are less likely than trench plate boundaries to have earthquakes within 100km. The liklihood of them having earthquakes is similar to transform faults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "results = analyze_ridge_likelihood_difference(earthquake_gdf_with_distances, distance_threshold=1000) #Analyze with distance threshold as 100\n",
    "for ridge_type, comparisons in results.items():\n",
    "    print(f\"Results for {ridge_type}:\")\n",
    "    for other_ridge, data in comparisons.items():\n",
    "        print(f\"  Compared to {other_ridge}:\")\n",
    "        print(f\"    Statistic: {data.get('statistic')}\")\n",
    "        print(f\"    P-value: {data.get('pvalue')}\")\n",
    "        print(f\"    Interpretation: {data['interpretation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the provided results for a 1000km radius, we can make the following statements about the likelihood of earthquakes occurring within 1000km of different ridge types:\n",
    "\n",
    "*   **Trenches vs. Ridges:** Earthquakes are significantly more likely to occur within 1000km of trenches compared to ridges. This remains consistent with the 100km analysis and reinforces the idea that trenches are associated with higher seismic activity over a broader area.\n",
    "*   **Transform Faults vs. Ridges:** Earthquakes are significantly more likely to occur within 1000km of transform faults compared to ridges. This also remains consistent with the 100km analysis, suggesting that transform faults have more widespread seismic activity compared to ridges.\n",
    "*   **Trenches vs. Transform Faults:** There is *no* statistically significant difference in earthquake likelihood between trenches and transform faults within 1000km.  This is a key difference from the 100km analysis.\n",
    "*   **Ridges vs. All Others:** There is *no* statistically significant difference in earthquake likelihood between ridges and either trenches or transform faults.\n",
    "\n",
    "**In summary,** these findings suggest a different hierarchy in terms of the likelihood of earthquakes occurring within 1000km of these plate boundary types:\n",
    "\n",
    "**Trenches ≈ Transform Faults > Ridges.**\n",
    "\n",
    "Specifically, we can say:\n",
    "\n",
    "1.  Earthquakes are generally more concentrated near both trenches and transform faults within a 1000km radius compared to ridges.\n",
    "2.  Trench plate boundaries are more likely than ridge plate boundaries to have earthquakes within 1000km.\n",
    "3.  Transform fault plate boundaries are more likely than ridge plate boundaries to have earthquakes within 1000km."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key differences between the 100km and 1000km analyses are:\n",
    "\n",
    "*   **Trenches and Transform Faults:** At 100km, trenches were significantly more likely to have nearby earthquakes than transform faults. At 1000km, this difference disappears, and the likelihood of earthquakes is similar for both. This suggests that the influence of trenches on earthquake occurrence extends further out but isn't necessarily more intense very close to the boundary compared to transform faults.\n",
    "*   **Overall Hierarchy:** At 100km, the hierarchy was Trenches > Transform Faults > Ridges. At 1000km, the hierarchy shifts to Trenches ≈ Transform Faults > Ridges. The distinction between trenches and transform faults becomes less clear at the larger distance.\n",
    "* **Interpretation:** At 1000km, the influence of a ridge plate boundary on how likely earthquakes are to occur significantly diminishes relative to other plates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "def analyze_mag_distance_correlation_by_boundary(df, mag_column='mag', distance_column='distance_to_plate_km', boundary_type_column='nearest_plate_boundary_t'):\n",
    "    \"\"\"\n",
    "    Calculates the Spearman rank correlation between magnitude and distance\n",
    "    separately for each plate boundary type.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing earthquake data.\n",
    "        mag_column (str): Name of the magnitude column.\n",
    "        distance_column (str): Name of the distance (in km) column.\n",
    "        boundary_type_column (str): Name of the boundary type column.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are boundary types and values are\n",
    "              dictionaries containing 'correlation' (Spearman's rho),\n",
    "              'p_value', and 'interpretation'.\n",
    "              Returns None for boundary types with insufficient data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Drop rows with NaN in relevant columns to avoid errors\n",
    "    df_clean = df.dropna(subset=[mag_column, distance_column, boundary_type_column]).copy()\n",
    "\n",
    "    boundary_types = df_clean[boundary_type_column].unique()\n",
    "    results = {}\n",
    "    alpha = 0.05  # Significance level\n",
    "\n",
    "    for b_type in boundary_types:\n",
    "        subset = df_clean[df_clean[boundary_type_column] == b_type]\n",
    "\n",
    "        # Need at least 3 data points for a meaningful correlation calculation\n",
    "        if len(subset) < 3:\n",
    "            results[b_type] = {\n",
    "                'correlation': None,\n",
    "                'p_value': None,\n",
    "                'interpretation': f\"Insufficient data points ({len(subset)}) for correlation.\"\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        # Calculate Spearman correlation and p-value\n",
    "        try:\n",
    "            correlation, p_value = stats.spearmanr(subset[mag_column], subset[distance_column])\n",
    "\n",
    "            # Interpret the result\n",
    "            interpretation = f\"Spearman Correlation (rho): {correlation:.3f}, P-value: {p_value:.3g}. \"\n",
    "            if p_value < alpha:\n",
    "                if correlation > 0.1: # Threshold for weak positive correlation\n",
    "                    interpretation += f\"There is a statistically significant weak-to-moderate positive correlation: higher magnitude earthquakes tend to occur slightly further from the {b_type} boundary.\"\n",
    "                elif correlation < -0.1: # Threshold for weak negative correlation\n",
    "                    interpretation += f\"There is a statistically significant weak-to-moderate negative correlation: higher magnitude earthquakes tend to occur slightly closer to the {b_type} boundary.\"\n",
    "                else:\n",
    "                     interpretation += f\"There is a statistically significant but very weak correlation (close to zero), suggesting little practical relationship.\"\n",
    "\n",
    "            else:\n",
    "                interpretation += f\"There is no statistically significant correlation between magnitude and distance for the {b_type} boundary.\"\n",
    "\n",
    "            results[b_type] = {\n",
    "                'correlation': correlation,\n",
    "                'p_value': p_value,\n",
    "                'interpretation': interpretation\n",
    "            }\n",
    "        except Exception as e: # Catch potential errors during calculation\n",
    "             results[b_type] = {\n",
    "                'correlation': None,\n",
    "                'p_value': None,\n",
    "                'interpretation': f\"Error during correlation calculation: {e}\"\n",
    "            }\n",
    "\n",
    "\n",
    "    return results\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Assuming 'earthquake_gdf_with_distances' is your DataFrame and\n",
    "# 'distance_to_plate_km' column exists.\n",
    "\n",
    "correlation_results = analyze_mag_distance_correlation_by_boundary(earthquake_gdf_with_distances)\n",
    "\n",
    "# Print the results clearly\n",
    "print(\"Correlation between Magnitude and Distance by Boundary Type:\\n\")\n",
    "for boundary_type, result in correlation_results.items():\n",
    "    print(f\"--- {boundary_type} ---\")\n",
    "    if result['correlation'] is not None:\n",
    "        print(f\"  Spearman's rho: {result['correlation']:.3f}\")\n",
    "        print(f\"  P-value: {result['p_value']:.3g}\") # Use general format for p-value display\n",
    "        print(f\"  Interpretation: {result['interpretation']}\")\n",
    "    else:\n",
    "        print(f\"  {result['interpretation']}\") # Print error or insufficient data message\n",
    "    print(\"-\" * (len(boundary_type) + 8) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Spearman correlation analysis results:\n",
    "\n",
    "*   **Overall Finding:** The dataset **does not show a significant simple monotonic relationship** (either consistently increasing or decreasing) between earthquake magnitude and the distance to the plate boundary for *any* of the three types analysed (ridge, trench, transform).\n",
    "\n",
    "*   **Ridge Boundary:**\n",
    "    *   Spearman's rho: 0.002 (, those results **absolutely make sense** statistically, and they tell a consistent story:\n",
    "\n",
    "1.  **Ridge (rho = 0.002, p = 0.915):**\n",
    "    *   The correlation coefficient (rho) is extremely close to zero, indicating practically no monotonic relationship in your sample data.\n",
    "    *   The p-value is very high (much greater than the typical 0.05 threshold). This means you cannot reject the null hypothesis (that there is no correlation).\n",
    "    *   **Conclusion:** Your data provides no statistically significant evidence that earthquake magnitude is related (either positively or negatively) to the distance from a ridge boundary.\n",
    "\n",
    "2.  **Trench (rho = 0.059, p = 0.0585):**\n",
    "    *   The correlation coefficient (rho) is still very small, suggesting only a very weak positive tendency in the sample (larger quakes slightly further away).\n",
    "    *   The p-value is *just* above the conventional 0.05 significance level.\n",
    "    *   **Conclusion:** Strictly speaking, using alpha = 0.05, this result is *not statistically significant*. You fail to reject the null hypothesis. While the p-value is borderline, the correlation itself is so weak that even if it *were* significant, it would likely indicate a negligible practical relationship. There's no strong evidence here for a link between magnitude and distance near trenches.\n",
    "\n",
    "3.  **Transform (rho = -0.012, p = 0.74):**\n",
    "    *   The correlation coefficient (rho) is extremely close to zero, indicating practically no monotonic relationship in your sample (a tiny negative tendency).\n",
    "    *   The p-value is very high. You cannot reject the null hypothesis.\n",
    "    *   **Conclusion:** Your data provides no statistically significant evidence that earthquake magnitude is related to the distance from a transform boundary.\n",
    "\n",
    "**Overall Interpretation:**\n",
    "\n",
    "Based on this Spearman correlation analysis, **your dataset does not show a significant simple monotonic relationship (either increasing or decreasing) between earthquake magnitude and the distance to the plate boundary for *any* of the three types (ridge, trench, transform).**\n",
    "\n",
    "**Does this make sense geologically?**\n",
    "\n",
    "It's plausible. While different boundary types have different mechanisms, the relationship between the magnitude of an earthquake and its precise location relative to the *surface trace* of the plate boundary might be complex and not simply monotonic:\n",
    "\n",
    "*   Large earthquakes can occur directly on the main fault but also on subsidiaryExtremely close to zero, indicating virtually no monotonic trend in the sample).\n",
    "    *   P-value: 0.915 (Very high, far exceeding the typical 0.05 significance threshold).\n",
    "    *   **Conclusion:** There is **no statistically significant evidence** from this data to suggest that earthquake magnitude is related to the distance from a ridge boundary.\n",
    "\n",
    "*   **Trench Boundary:**\n",
    "    *   Spearman's rho: 0.059 (Very weak positive tendency in the sample).\n",
    "    *   P-value: 0.0585 (Borderline, slightly above the conventional 0.05 significance level).\n",
    "    *   **Conclusion:** Strictly using α = 0.05, this result is **not statistically significant**. Even if it were significant, the correlation is very weak, suggesting little practical relationship between magnitude and distance near trenches based on this analysis.\n",
    "\n",
    "*   **Transform Boundary:**\n",
    "    *   Spearman's rho: -0.012 (Extremely close to zero, indicating virtually no monotonic trend in the sample).\n",
    "    *   P-value: 0.74 (Very high).\n",
    "    *   **Conclusion:** There is **no statistically significant evidence** from this data to suggest that earthquake magnitude is related to the distance from a transform boundary.\n",
    "\n",
    "**Geological Plausibility:**\n",
    "\n",
    "*   These results are plausible. The relationship between earthquake magnitude and its precise location relative to the plate boundary's surface trace can be complex.\n",
    "*   Factors like earthquake depth (especially for trenches), the presence of subsidiary faults, and complex stress patterns mean that the largest earthquakes don't necessarily occur systematically faults nearby.\n",
    "*   For trenches, the depth of the earthquake along the subducting slab is often more critical than the surface distance to the trench axis, and large events can occur at various depths/distances.\n",
    "*   Stress accumulation and release patterns might be complex, meaning the largest events don't necessarily happen right at the boundary or systematically further away.\n",
    "\n",
    "So, yes, finding near-zero, non-significant correlations is a perfectly reasonable outcome for this type of analysis. It suggests that if a relationship exists, it's likely more complex than a simple \"bigger quakes are always closer/further\" trend captured by Spearman correlation, or that other factors are much more dominant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance From Nearest Plate Ridge and Magnitude Analysis and Exploration\n",
    "***Reusing functions from above with different input column***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake_gdf_with_distances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_ridge_distance_likelihood_combined(earthquake_gdf_with_distances, distance_column='distance_to_plate', boundary_type_column='nearest_plate_geogdesc', distance_thresholds=[100, 250, 500, 1000, 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Now call the function with the desired column\n",
    "visualize_ridge_distance_likelihood_combined(\n",
    "    earthquake_gdf_with_distances,\n",
    "    distance_column='distance_to_plate',\n",
    "    boundary_type_column='nearest_plate_geogdesc', # Use the alternative column\n",
    "    distance_thresholds=[100, 250, 500, 1000, 2000],\n",
    "    minmag=5.0,\n",
    "    color_by='nearest_plate_boundary_t'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
